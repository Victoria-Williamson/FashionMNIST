{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the dataset \n",
    "x_train = x_train.reshape(x_train.shape[0], 28,28, 1).astype('float32')\n",
    "x_train = ( x_train - 127.5) / 127.5 \n",
    "\n",
    "# Adding channels dimension\n",
    "x_train = np.expand_dims(x_train, axis = 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pyplot.gcf()\n",
    "fig.set_size_inches(25, 10.5)\n",
    "fig.savefig('test2png.png', dpi=100)\n",
    "\n",
    "for i in range(9):\n",
    "\tpyplot.subplot(1,9,i + 1)\n",
    "\tpyplot.imshow(x_train[i],cmap=pyplot.get_cmap('gray'))\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = tf.data.Dataset.from_tensor_slices(x_train).shuffle(len(x_train)).batch(256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Discriminator\n",
    "\n",
    "The purpose of a discriminator in a GAN is to determine how realistic an image looks. To do this both the real images from the training set, and generated images from the generator are passed into this model. By doing this the model is able to learn how to predict the likelihood that an image is real or not. This feature is very important, because it allows us to make sure that our generator produces realistic images. \n",
    "\n",
    "This discriminator takes in a 28 x 28 x 1 image and at the end will ouput the probabillity that an image is real. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    # Defining the model \n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Input Layer\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    # Hidden Layers\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Define Optimization function\n",
    "    opt = tf.keras.optimizers.Adam(lr=2e-4, beta_1=0.5)\n",
    "\n",
    "    # Compile Model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the generator\n",
    "\n",
    "The purpose of the generator is to generate data that could plausibly be from the original dataset. It's essentially trying to fool the discriminator. To do so, we will start with a vector that contains random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(latent_vec_dim):\n",
    "    # Defining the model\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Input layer, takes in a vector with latent_dim dimensions \n",
    "    # and has enough nodes for multiple versions of low resolution\n",
    "    # images. Picking a standard number like 128, we need 256x28x28 nodes.\n",
    "    num_nodes = 256*28*28\n",
    "    \n",
    "    model.add(layers.Dense(num_nodes, input_dim = latent_vec_dim))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Reshape(7,7,128))\n",
    "    \n",
    "    # now upsample the low res 7x7 image to 14x14 image\n",
    "    model.add(layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # upsample to 28x28\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(1, (7,7), activation='sigmoid', padding='same'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan(disc, gen):\n",
    "    disc.trainable = false\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(gen)\n",
    "    model.add(disc)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1 = 0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
