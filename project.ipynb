{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets.fashion_mnist import load_data\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Reshape\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    (trainX, _), (_, _) = load_data()\n",
    "    dataset = np.expand_dims(trainX, axis=-1)\n",
    "    dataset = dataset.astype('float32')\n",
    "    dataset = dataset / 255.0\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pyplot.gcf()\n",
    "fig.set_size_inches(25, 10.5)\n",
    "fig.savefig('test2png.png', dpi=100)\n",
    "x_train = load_dataset()\n",
    "\n",
    "for i in range(9):\n",
    "    pyplot.subplot(1,9,i + 1)\n",
    "    pyplot.imshow(x_train[i],cmap=pyplot.get_cmap('gray'))\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Discriminator\n",
    "\n",
    "The purpose of a discriminator in a GAN is to determine how realistic an image looks. To do this both the real images from the training set, and generated images from the generator are passed into this model. By doing this the model is able to learn how to predict the likelihood that an image is real or not. This feature is very important, because it allows us to make sure that our generator produces realistic images. \n",
    "\n",
    "This discriminator takes in a 28 x 28 x 1 image and at the end will ouput the probabillity that an image is real. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(in_shape=(28,28,1)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3,3), strides=(2,2), padding='same', input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(64, (3,3), strides=(2,2), padding='same'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    adam = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the generator\n",
    "\n",
    "The purpose of the generator is to generate data that could plausibly be from the original dataset. It's essentially trying to fool the discriminator. To do so, we will start with a vector, of latent_vecc_dim dimensions, that is instantiated with random values. The generator takes this vector and creates a set of low resolution images. We want it to be a set so the generator has space to combine values in multiple ways and learn from that.\n",
    "\n",
    "Once that is done, the images are eventually upsampled to the target resolution 28 x 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(latent_vec_dim):\n",
    "    # Defining the model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input layer, takes in a vector with latent_dim dimensions \n",
    "    # and has enough nodes for multiple versions of low resolution\n",
    "    # images. Picking a standard number like 128, we need 256x28x28 nodes.\n",
    "    num_nodes = 128*7*7\n",
    "    \n",
    "    model.add(Dense(num_nodes, input_dim = latent_vec_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((7,7,128)))\n",
    "    \n",
    "    # now upsample the low res 7x7 image to 14x14 image\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # upsample to 28x28\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(1, (7,7), activation='sigmoid', padding='same'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the GAN\n",
    "\n",
    "The GAN is a compound model consisting of the generator and then the discriminator in that order. The discriminator is not trainable in the GAN because we are targeting the generator, and having weights that change in the discriminator after every datapoint is not a viable way of training it. That being said the discriminator does get trained every epoch, just not here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan(disc, gen):\n",
    "    disc.trainable = False\n",
    "    \n",
    "    model =Sequential()\n",
    "    model.add(gen)\n",
    "    model.add(disc)\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.0002, beta_1 = 0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_samples(dataset, num_samples):\n",
    "    ix = np.random.randint(0, dataset.shape[0], num_samples)\n",
    "    X = dataset[ix]\n",
    "    y = np.ones((num_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_vec(latent_vec_dim, num_vec):\n",
    "    latent_vecs = np.random.randn(latent_vec_dim * num_vec)\n",
    "    latent_vecs = latent_vecs.reshape(num_vec, latent_vec_dim)\n",
    "    return latent_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(generator, latent_vec_dim, num_vec):\n",
    "    latent_vecs = generate_latent_vec(latent_vec_dim, num_vec)\n",
    "    X = generator.predict(latent_vecs)\n",
    "    y = np.zeros((num_vec, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does an untrained generator generate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vec_dim = 100\n",
    "gen = generator(latent_vec_dim)\n",
    "X, _ = generate_samples(gen, latent_vec_dim, 25)\n",
    "for i in range(25):\n",
    "    pyplot.subplot(5, 5, 1 + i)\n",
    "    pyplot.axis('off')\n",
    "    pyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Now that we have the individual components ready we should train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=256):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    for i in trange(n_epochs):\n",
    "        for j in trange(bat_per_epo):\n",
    "            X_real, y_real = pick_samples(dataset, half_batch)\n",
    "            X_fake, y_fake = generate_samples(g_model, latent_dim, half_batch)\n",
    "            X, y = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))\n",
    "            d_loss, _ = d_model.train_on_batch(X, y)\n",
    "            X_gan = generate_latent_vec(latent_dim, n_batch)\n",
    "            y_gan = np.ones((n_batch, 1))\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vec_dim = 100\n",
    "disc = discriminator()\n",
    "gen = generator(latent_vec_dim)\n",
    "gan = gan(disc, gen)\n",
    "dataset = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(gen, disc, gan, dataset, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = generate_samples(gen, latent_vec_dim, 25)\n",
    "for i in range(25):\n",
    "    pyplot.subplot(5, 5, 1 + i)\n",
    "    pyplot.axis('off')\n",
    "    pyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'fashion_mnist_generator.h5'\n",
    "gen.save(filename)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
